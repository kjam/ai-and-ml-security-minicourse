{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Adversarial Examples\n",
    "\n",
    "In this notebook, you'll learn about the field of adversarial learning, where you exploit the way deep learning systems work to:\n",
    "\n",
    "- make the prediction false\n",
    "- steer the prediction in a direction of your choosing\n",
    "\n",
    "Although you can create many types of adversarial examples, we'll use [foolbox](https://github.com/bethgelab/foolbox) to generate adversarial images and test them with a [ResNet50](https://en.wikipedia.org/wiki/Residual_neural_network) model trained on [ImageNet](https://en.wikipedia.org/wiki/ImageNet) data -- so that we can then \"see\" the adversarial attack!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import foolbox\n",
    "import keras\n",
    "import numpy as np\n",
    "import eagerpy as ep\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.applications.resnet50 import ResNet50, \\\n",
    "    preprocess_input, decode_predictions\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "from foolbox.criteria import Misclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you will use this later to investigate image labels\n",
    "import json\n",
    "class_idx = json.load(open('data/imagenet_class_index.json'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note: If you are using connected internet can use this line!\n",
    "\n",
    "kmodel=ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the ResNet Model\n",
    "\n",
    "First, let's take a look at how the model works normally with some examples in this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "img_path = 'data/img/cat.jpg'\n",
    "img = load_img(img_path, target_size=(224, 224))\n",
    "\n",
    "x = img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds = kmodel.predict(x)\n",
    "\n",
    "for pred in decode_predictions(preds, top=3)[0]:\n",
    "    print(pred)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn\n",
    "\n",
    "- Try a few of the other photos in the photo directory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/0301_shark.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Attack\n",
    "\n",
    "Foolbox has a variety of attacks to choose from. First, you need to initialize the model within Foolbox to allow foolbox to access the model's underlying weights/biases and outputs in order to build attacks appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialize foolbox model\n",
    "\n",
    "# ::-1 reverses the color channels, \n",
    "# because Keras ResNet50 expects BGR instead of RGB\n",
    "preprocessing = dict(flip_axis=-1, mean=[104.0, 116.0, 123.0])\n",
    "\n",
    "fmodel = foolbox.models.TensorFlowModel(kmodel, \n",
    "                                   bounds=(0, 255), \n",
    "                                   preprocessing=preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can grab a set of images and labels to use for the attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images, labels = ep.astensors(*foolbox.samples(fmodel, dataset=\"imagenet\", batchsize=16))\n",
    "clean_acc = foolbox.accuracy(fmodel, images, labels)\n",
    "print(f\"clean accuracy:  {clean_acc * 100:.1f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast Gradient Sign Method Attack\n",
    "\n",
    "You'll use first a very popular attack called the Fast-Gradient Sign Method, that exploits the gradients of the model to \"climb\" rather than \"descend\" the gradient. It then generates an adversarial image by adding small noise perturbations to the image to make the model misclassify the image.\n",
    "\n",
    "\n",
    "This attack was first discovered by [Goodfellow et al., 2014](https://arxiv.org/abs/1412.6572)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# these epsilons steer \"how much noise\": bigger epsilon, bigger noise \n",
    "# NOTE: the epsilons are expected to be floats between 0 and 1 and apply to the noise \"clipping\"\n",
    "\n",
    "epsilons=[0.1, 0.3, 0.5]\n",
    "attack = foolbox.attacks.FGSM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_advs, adversarial_images, success = attack(fmodel, images, labels, epsilons=epsilons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title('Original')\n",
    "example_image = images[1].numpy() / 255\n",
    "# division by 255 to convert [0, 255] to [0, 1]\n",
    "plt.imshow(example_image)  \n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title('Adversarial')\n",
    "adversarial_image = adversarial_images[2][1].numpy() / 255 # you can edit the indexing here to view different attack successes\n",
    "plt.imshow(adversarial_image)  \n",
    "# ::-1 to convert BGR to RGB\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title('Difference')\n",
    "difference = adversarial_image - example_image\n",
    "plt.imshow(difference / abs(difference).max() * 0.2 + 0.5)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Turn\n",
    "\n",
    "- Did it work? What was the predicted label?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_x = np.expand_dims(adversarial_images[2][1].numpy().copy(), axis=0) # you can edit the indexing here to view different attack successes\n",
    "adv_x = preprocess_input(adv_x)\n",
    "\n",
    "img_x = np.expand_dims(images[1].numpy().copy(), axis=0)\n",
    "img_x = preprocess_input(img_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/02_adversarial_vs_original_predictions.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Turn\n",
    "\n",
    "- Now try and make an adversarial attack using a different attack method. See all attacks here: https://foolbox.readthedocs.io/en/latest/modules/attacks.html\n",
    "- Some of the attacks will need you to define Criteria (example below)\n",
    "- You may also try a targeted class attack: (see: https://foolbox.readthedocs.io/en/latest/modules/criteria.html#foolbox.criteria.TargetClass and classes with labels https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "index = random.choice(range(17, 1000, 1))\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "example_images, labels = ep.astensors(*foolbox.samples(fmodel, dataset=\"imagenet\", batchsize=16, index=index))\n",
    "\n",
    "for label in labels.numpy():\n",
    "    print(class_idx[str(label)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick which one you want and add it to the index\n",
    "example_image, label = ep.astensors(*foolbox.samples(fmodel, dataset=\"imagenet\", batchsize=1, index=index+4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = Misclassification(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "\n",
    "- Build your attack and generate the adversarial images (like you did above)\n",
    "- Test the predictions on any successes\n",
    "- Choose one or two to visually inspect\n",
    "\n",
    "Reuse the code above, or write your own! There are also some small solution codes if you want to load them and play around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %load solutions/0303_carliniwagner_attack.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %load solutions/0304_test_predictions.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %load solutions/0305_plot_examples.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
